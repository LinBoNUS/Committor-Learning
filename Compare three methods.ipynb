{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c11f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from torch import nn\n",
    "torch.set_default_dtype(torch.float64)\n",
    "import torch.nn.functional as func\n",
    "\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8583155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from Example1 import Mueller_System\n",
    "from utils    import LangevinIntegrator,rL2,Model,Model_cpu,Solver,Metadynamics,Metadynamics_Extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018a7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc48ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS = Mueller_System(); EPS = 10;\n",
    "LI  = LangevinIntegrator(dim=SYS.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185c15b",
   "metadata": {
    "code_folding": [
     0,
     3,
     9
    ]
   },
   "outputs": [],
   "source": [
    "def get_q_NN(X,model_name=-1): \n",
    "    if model_name!=-1: model.load_weights(model_name);\n",
    "    return model.get_q(X).reshape(-1)\n",
    "def replace_lines(file_name, line_num, text):\n",
    "    lines = open(file_name, 'r').readlines()\n",
    "    for k in range(len(line_num)): lines[line_num[k]] = text[k]\n",
    "    out = open(file_name, 'w')\n",
    "    out.writelines(lines)\n",
    "    out.close()  \n",
    "def get_q_FEM(X,m=200,mb=50,file_name='MU_2D.edp'):\n",
    "    eps=EPS\n",
    "    random_id = np.random.randint(1e8)\n",
    "    file_name0 = file_name\n",
    "    file_name  = file_name[:-4] + str(random_id) + file_name[-4:]\n",
    "    ! cp $file_name0 $file_name\n",
    "    np.savetxt(\"X\"+str(random_id),X[:,:2])\n",
    "    replace_lines(file_name,[0,10,22,23],[\"real eps=\"+str(eps)+\";\\n\",\"int m=%d,mb=%d;\\n\"%(m,mb),\n",
    "                                          \"ifstream fin(\\\"X\"+str(random_id) + \"\\\");\\n\",\n",
    "                                          \"ofstream fout(\\\"q\"+str(random_id) + \"\\\");\\n\"])\n",
    "    !FreeFem++ $file_name > FEM.log\n",
    "    os.remove(\"X\"+str(random_id))\n",
    "    os.remove(file_name)\n",
    "    q = np.loadtxt(\"q\"+str(random_id)).reshape(-1)\n",
    "    os.remove(\"q\"+str(random_id))\n",
    "    return q[:len(X)] # may output len(X)+1 values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131594f",
   "metadata": {},
   "source": [
    "# Read some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96b481",
   "metadata": {
    "code_folding": [
     0,
     6,
     12,
     18
    ]
   },
   "outputs": [],
   "source": [
    "def get_X_A(n,w=2*SYS.sigma*np.sqrt(EPS)):\n",
    "    X = np.random.uniform(SYS.A[0]-SYS.r,SYS.A[0]+SYS.r,(10*n,SYS.dim))\n",
    "    X[:,1] = np.random.uniform(SYS.A[1]-SYS.r,SYS.A[1]+SYS.r,(10*n))\n",
    "    X[:,2:] = np.random.uniform(-w,w,(10*n,SYS.dim-2))\n",
    "    mask = SYS.IsInA(X)\n",
    "    return X[mask][:n]\n",
    "def get_X_B(n,w=2*SYS.sigma*np.sqrt(EPS)):\n",
    "    X = np.random.uniform(SYS.B[0]-SYS.r,SYS.B[0]+SYS.r,(10*n,SYS.dim))\n",
    "    X[:,1] = np.random.uniform(SYS.B[1]-SYS.r,SYS.B[1]+SYS.r,(10*n))\n",
    "    X[:,2:] = np.random.uniform(-w,w,(10*n,SYS.dim-2))\n",
    "    mask = SYS.IsInB(X)\n",
    "    return X[mask][:n]\n",
    "def get_min_V_2D():\n",
    "    xx = np.linspace(-.8,-.3,1000)\n",
    "    yy = np.linspace(1.2,1.7,1000)\n",
    "    XX,YY  = np.meshgrid(xx,yy)\n",
    "    x_list = np.concatenate([XX[:,:,None],YY[:,:,None]],axis=-1).reshape(-1,2)\n",
    "    return SYS.get_V_2D(x_list).min()\n",
    "def get_uniform_data(N,Vbar=130):\n",
    "    sigma     = SYS.sigma*np.sqrt(EPS)\n",
    "    data      = np.random.uniform(-2*sigma,2*sigma,(N*10,SYS.dim))\n",
    "    data[:,0] = np.random.uniform(SYS.xrange[0],SYS.xrange[1],N*10)\n",
    "    data[:,1] = np.random.uniform(SYS.yrange[0],SYS.yrange[1],N*10)\n",
    "    mask      = (SYS.get_V_2D(data[:,:2])-get_min_V_2D())<Vbar;\n",
    "    return data[mask][:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aff1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u = get_uniform_data(int(1e5))\n",
    "q_u = get_q_FEM(X_u);\n",
    "def Error_Model(model): return rL2(q_u,model.get_q(X_u))\n",
    "mask = abs(q_u-0.5)<0.2; X_u2 = X_u[mask]; q_u2 = q_u[mask];\n",
    "def Error_Model2(model): return rL2(q_u2,model.get_q(X_u2))\n",
    "print(X_u.shape,X_u2.shape)\n",
    "\n",
    "X_A = get_X_A(5000)\n",
    "X_B = get_X_B(5000)\n",
    "print(X_A.shape,X_B.shape)\n",
    "def E_AB(model): return np.sqrt(np.mean(model.get_q(X_A)**2))+np.sqrt(np.mean((1-model.get_q(X_B))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa831cad",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "def mask_fn(X): return (SYS.get_V(X)-SYS.get_V(X).min())<130; \n",
    "def ShowQandSampledData(q_fn,mask_fn=mask_fn,xrange=SYS.xrange,yrange=SYS.yrange,dim=SYS.dim,nx=100,ny=100,\n",
    "                states=[],titles=[],q_list=np.linspace(.1,.9,9),fig_name=None):\n",
    "    xx     = np.linspace(xrange[0],xrange[1],nx)\n",
    "    yy     = np.linspace(yrange[0],yrange[1],ny)\n",
    "    XX,YY  = np.meshgrid(xx,yy)\n",
    "    x_list = np.concatenate([XX[:,:,None],YY[:,:,None]],axis=-1).reshape(-1,2)\n",
    "    x_list = np.hstack([x_list,np.zeros(dtype=np.float64,shape=(x_list.shape[0],dim-2))])\n",
    "    mask   = mask_fn(x_list); \n",
    "    V      = SYS.get_V(x_list); V[~mask] = np.nan;\n",
    "    num    = len(q_fn)\n",
    "    fig,ax = plt.subplots(1,num,figsize=(4.5*num,4),constrained_layout=True)\n",
    "    for k in range(num):\n",
    "        q  = q_fn[k](x_list); q[~mask] = np.nan;\n",
    "        c1 = ax[k].contour(XX,YY,q.reshape(XX.shape),q_list,colors='black',linestyles='solid',linewidths=2);  \n",
    "        ax[k].clabel(c1, inline=1, fontsize=10)\n",
    "        if len(states)>0 and len(states[k])>0: [ax[k].scatter(d[:,0],d[:,1],s=1) for d in states[k]]\n",
    "        \n",
    "        ax[k].contour(XX,YY,V.reshape(XX.shape),5,colors='grey',linestyles='dashed',linewidths=.7);  \n",
    "        ax[k].add_artist(plt.Circle(SYS.A, SYS.r, color='k'))\n",
    "        ax[k].add_artist(plt.Circle(SYS.B, SYS.r, color='k'))\n",
    "        ax[k].text(SYS.A[0]-0.1, SYS.A[1]+0.15, '$A$', fontsize=20)\n",
    "        ax[k].text(SYS.B[0]+0.1, SYS.B[1]-0.20, '$B$', fontsize=20)\n",
    "        ax[k].set_xlabel('$x_1$', fontsize=18)\n",
    "        if k==0: ax[k].set_ylabel('$x_2$', fontsize=18, rotation=0)\n",
    "        ax[k].tick_params(axis=\"both\", labelsize=10) \n",
    "        ax[k].set_xlim(xrange)\n",
    "        ax[k].set_ylim(yrange)\n",
    "        if len(titles)>0: ax[k].set_title(titles[k],fontsize=20)\n",
    "\n",
    "    if fig_name is not None: plt.savefig(fig_name,dpi=300)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d6cbe5",
   "metadata": {},
   "source": [
    "# Obtain a NN close to $q$ Using SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6eefa",
   "metadata": {
    "code_folding": [
     0,
     1,
     3,
     6,
     11
    ]
   },
   "outputs": [],
   "source": [
    "class Commitor_Solver_SL():\n",
    "    def __init__(self,model): \n",
    "        self.model    = model\n",
    "    def sample_batch(self,data,batch_size):\n",
    "        idx = random.sample(range(len(data)),  min(batch_size,len(data)))\n",
    "        return data[idx]\n",
    "    def get_loss(self,data): \n",
    "        X,q  = data[:,:self.model.input_dim],data[:,-1]\n",
    "        qNN  = self.model.get_q(X)\n",
    "        loss = torch.mean((qNN-q)**2)\n",
    "        return loss,loss \n",
    "    def train_model(self,data_train,data_test,batch_size,optimizer,n_steps,\n",
    "                    scheduler=None,n_show_loss=100,terminal_condition=None,\n",
    "                    error_model1=None,error_model2=None,use_tqdm=True):\n",
    "        \n",
    "        if use_tqdm: step_range = tqdm(range(n_steps))\n",
    "        else: step_range = range(n_steps)\n",
    "        loss_step = []\n",
    "        for i_step in step_range:\n",
    "            if i_step%n_show_loss==0:\n",
    "                loss_train,loss_test = self.get_loss(data_train)[:-1],\\\n",
    "                                       self.get_loss(data_test)[:-1]\n",
    "\n",
    "                def show_num(x): \n",
    "                    if abs(x)<100 and abs(x)>.01: return '%0.5f'%x\n",
    "                    else: return '%0.2e'%x\n",
    "                item1 = '%2dk'%np.int_(i_step/1000)\n",
    "                item2 = 'Loss: '+' '.join([show_num(k) for k in loss_train])\n",
    "                item3 = ' '.join([show_num(k) for k in loss_test])\n",
    "                item4 = ''\n",
    "                if error_model1 is not None:\n",
    "                    item4 = 'Error: '+show_num(error_model1(self.model))\n",
    "                    if error_model2 is not None:\n",
    "                        item4 = item4 + ' '+show_num(error_model2(self.model))\n",
    "                print(', '.join([item1,item2,item3,item4]))\n",
    "                loss_step = loss_step + [i_step] + [float(k) for k in loss_train]\\\n",
    "                                                 + [float(k) for k in loss_train]\n",
    "            \n",
    "            data_batch = self.sample_batch(data_train,batch_size)\n",
    "            loss       = self.get_loss(data_batch)[-1]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None: scheduler.step()\n",
    "            if terminal_condition is not None:\n",
    "                if terminal_condition(self.model): return\n",
    "        return loss_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ef915",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "X_SL = get_uniform_data(int(1e5))\n",
    "q_SL = get_q_FEM(X_SL)\n",
    "print(X_SL.shape,q_SL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n         = 5;\n",
    "model     = Model_cpu(input_dim=SYS.dim,num_hidden=2,hidden_dim=50,n=n)\n",
    "solver_SL = Commitor_Solver_SL(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.hstack([X_SL,q_SL.reshape(-1,1)])\n",
    "data_train = torch.tensor(data_train)\n",
    "data_test  = data_train\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=torch.tensor(1e-3))\n",
    "solver_SL.train_model(data_train=data_train,data_test=data_test,batch_size=5000,\n",
    "                      optimizer=optimizer,n_steps=int(5e4+1),n_show_loss=1000,use_tqdm=True,\n",
    "                      error_model1=Error_Model,error_model2=E_AB,)\n",
    "ShowQandSampledData([model.get_q,model.get_r],states=[[X_SL],[]])\n",
    "\n",
    "torch.save(model.state_dict(), \"saved_models/SL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b710d7",
   "metadata": {},
   "source": [
    "# Some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06fe65",
   "metadata": {
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "def down_sample(X):\n",
    "    mask = SYS.IsInA(X) | SYS.IsInB(X)\n",
    "    return X[~mask]\n",
    "def get_train_test(X,coef,X_A,X_B,ratio=0.7):\n",
    "    Xc         = np.hstack([X,coef.reshape(-1,1)])\n",
    "    data_train = []\n",
    "    data_test  = []\n",
    "    for d,requires_grad in [[Xc,True],[X_A,False],[X_B,False]]:\n",
    "        perm = np.random.permutation(len(d))\n",
    "        d1 = d[perm[:int(len(d)*ratio)]]\n",
    "        data_train.append(torch.tensor(d1,requires_grad=requires_grad))\n",
    "        d2 = d[perm[int(len(d)*ratio):]]\n",
    "        data_test.append(torch.tensor(d2,requires_grad=requires_grad))\n",
    "    return data_train,data_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########     training details  ##########################\n",
    "c1 = 1;  c2 = 1; learning_rate = 1e-4;                   #\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985e0f4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def show_distr(X,ax):\n",
    "    ax.scatter(X[:,0],X[:,1],s=1);\n",
    "    ax.set_xlim(SYS.xrange); ax.set_ylim(SYS.yrange)\n",
    "    ax.set_xlabel(r'$x_1$'); ax.set_ylabel(r'$x_2$',rotation=1)\n",
    "    ax.set_title('shape:'+str(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c3d8a",
   "metadata": {},
   "source": [
    "# Sampling Scheme I and II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1bc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "n      = 10;\n",
    "model  = Model_cpu(input_dim=SYS.dim,num_hidden=2,hidden_dim=50,n=n)\n",
    "solver = Solver(model,q0=-5,q1=5)\n",
    "meta   = Metadynamics(model=model,h=2,w=.003)\n",
    "\n",
    "# start from SL NN\n",
    "\n",
    "model.load_state_dict(torch.load(\"saved_models/SL\"))\n",
    "ShowQandSampledData([model.get_q,model.get_r],titles=[r'$q$',r'$r$'])\n",
    "\n",
    "# run metadyanmics\n",
    "\n",
    "meta.re_init()\n",
    "meta.perform(dV=SYS.get_dV,x=SYS.A.reshape(1,-1),dt=1e-5,eps=EPS,\n",
    "             N=int(1e6),N_add=500,show_freq=.5,use_tqdm=True,show_distr=show_distr)\n",
    "meta.show_meta(show_distr)\n",
    "\n",
    "# Sample data\n",
    "\n",
    "def get_f(X): return -SYS.get_dV(X) - meta.get_dV(X)\n",
    "X0  = np.repeat(SYS.A.reshape(1,-1),50,axis=0)\n",
    "X   = LI.get_data(X0,get_f,eps=EPS,dt=1e-5,m=100,T0=1,T=2,use_tqdm=True);\n",
    "X   = down_sample(X) \n",
    "fig,ax = plt.subplots(1,1,figsize=(3,3))\n",
    "show_distr(X,ax)\n",
    "plt.show()\n",
    "\n",
    "V_add = meta.get_V(X)\n",
    "coef  = np.exp(1/EPS*(V_add-V_add.max()))\n",
    "coef  = coef/coef.mean()\n",
    "\n",
    "# Further training\n",
    "\n",
    "data_train,data_test = get_train_test(X,coef,X_A,X_B,ratio=.9)\n",
    "for i in range(len(data_train)): print(data_train[i].shape,data_test[i].shape)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=torch.tensor(learning_rate))\n",
    "solver.train_model(data_train=data_train,data_test=data_test,c1=c1,c2=c2,batch_size=5000,\n",
    "                   optimizer=optimizer,n_steps=int(2e4+1),n_show_loss=1000,use_tqdm=True,\n",
    "                   error_model1=Error_Model,error_model2=Error_Model2)\n",
    "ShowQandSampledData([get_q_FEM,model.get_q],states=[[],[X]],\n",
    "                    titles=['Ref.','Sampling Scheme I'])\n",
    "\n",
    "torch.save(meta,'saved_models/SL_alg1_meta')\n",
    "torch.save([X,coef],'meta_data/SL_alg1_X_coef')\n",
    "torch.save(model.state_dict(), 'saved_models/SL_alg1_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbbc33b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n      = 10;\n",
    "model  = Model_cpu(input_dim=SYS.dim,num_hidden=2,hidden_dim=50,n=n)\n",
    "solver = Solver(model,q0=-5,q1=5)\n",
    "meta   = Metadynamics_Extend(model=model,h=2,w=.003,eps=EPS)\n",
    "\n",
    "# start from SL NN\n",
    "\n",
    "model.load_state_dict(torch.load(\"saved_models/SL\"))\n",
    "ShowQandSampledData([model.get_q,model.get_r],titles=[r'$q$',r'$r$'])\n",
    "\n",
    "# run metadyanmics\n",
    "\n",
    "meta.re_init()\n",
    "meta.perform(dV=SYS.get_dV,x=SYS.A.reshape(1,-1),dt=1e-5,eps=EPS,\n",
    "             N=int(1e6),N_add=500,show_freq=.5,use_tqdm=True,show_distr=show_distr)\n",
    "meta.show_meta(show_distr)\n",
    "\n",
    "# Sample data\n",
    "\n",
    "def get_f(X): return -SYS.get_dV(X) + meta.get_dF(X)/2\n",
    "X0  = np.repeat(SYS.A.reshape(1,-1),50,axis=0)\n",
    "X   = LI.get_data(X0,get_f,eps=EPS,dt=1e-5,m=100,T0=1,T=2,use_tqdm=True);\n",
    "X   = down_sample(X) \n",
    "fig,ax = plt.subplots(1,1,figsize=(3,3))\n",
    "show_distr(X,ax)\n",
    "plt.show()\n",
    "\n",
    "V_add = -meta.get_F(X)/2\n",
    "coef  = np.exp(1/EPS*(V_add-V_add.max()))\n",
    "coef  = coef/coef.mean()\n",
    "\n",
    "# Further training\n",
    "\n",
    "data_train,data_test = get_train_test(X,coef,X_A,X_B,ratio=.9)\n",
    "for i in range(len(data_train)): print(data_train[i].shape,data_test[i].shape)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=torch.tensor(learning_rate))\n",
    "solver.train_model(data_train=data_train,data_test=data_test,c1=c1,c2=c2,batch_size=5000,\n",
    "                   optimizer=optimizer,n_steps=int(2e4+1),n_show_loss=1000,use_tqdm=True,\n",
    "                   error_model1=Error_Model,error_model2=Error_Model2)\n",
    "ShowQandSampledData([get_q_FEM,model.get_q],states=[[],[X]],\n",
    "                    titles=['Ref.','Sampling Scheme II'])\n",
    "\n",
    "torch.save(meta,'saved_models/SL_alg2_meta')\n",
    "torch.save([X,coef],'meta_data/SL_alg2_X_coef')\n",
    "torch.save(model.state_dict(), 'saved_models/SL_alg2_Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d875a16",
   "metadata": {},
   "source": [
    "# Umbrella Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88371c1c",
   "metadata": {
    "code_folding": [
     0,
     1,
     20,
     32
    ]
   },
   "outputs": [],
   "source": [
    "class UmbrellaSampling():\n",
    "    def __init__(self,kappa,q,eps,model):\n",
    "        self.L     = len(q);\n",
    "        self.kappa = kappa;\n",
    "        self.q     = q;\n",
    "        self.eps   = eps;\n",
    "        self.model = model;\n",
    "    def get_phi(self,X,l): \n",
    "        return np.exp(-1/self.eps*self.kappa*(self.model.get_q(X)-self.q[l])**2).reshape(-1)\n",
    "    def get_gradphi_phi_Parallel(self,X,q):\n",
    "        qv,qx = self.model.get_q_qx(X)\n",
    "        return -1/self.eps*self.kappa*2*(qv.reshape(-1,1)-q)*qx\n",
    "    def get_data_Parallel(self,x0,get_dV,n=2,dt=1e-2,m=100,T0=1,T=10):\n",
    "        x0   = np.repeat(x0,n,axis=0)\n",
    "        q    = np.repeat(self.q,n,axis=0).reshape(-1,1)\n",
    "        def f(X,q=q): return -get_dV(X)+self.eps*self.get_gradphi_phi_Parallel(X,q)\n",
    "        data = LI.get_data(x0=x0,f=f,eps=self.eps,dt=dt,m=m,T0=T0,T=T)\n",
    "        nL   = x0.shape[0]\n",
    "        data = np.hstack([data[k*nL:k*nL+nL].reshape(self.L,-1) for k in range(int(data.shape[0]/nL))])\n",
    "        return [k.reshape(-1,x0.shape[1]) for k in data]\n",
    "    def get_z(self,data):\n",
    "        F = np.zeros(dtype=np.float64,shape=(self.L,self.L))\n",
    "        for i in range(self.L):\n",
    "            sum_phi_i = 0\n",
    "            for j in range(self.L):\n",
    "                sum_phi_i = sum_phi_i + self.get_phi(data[i],j)\n",
    "            for j in range(self.L):\n",
    "                F[i,j] = np.mean(self.get_phi(data[i],j)/sum_phi_i)\n",
    "        F_t = np.transpose(F)\n",
    "        F_t = F_t - np.identity(self.L)\n",
    "        F_t[-1]=1; b=np.zeros(self.L); b[-1]=1\n",
    "        return np.linalg.solve(F_t,b)\n",
    "    def get_X_coef(self,data):\n",
    "        Z    = self.get_z(data); X = np.vstack(data);\n",
    "        coef = []; \n",
    "        for l,k in enumerate(Z): coef=coef+[k/data[l].shape[0]*X.shape[0]]*data[l].shape[0]\n",
    "        coef = np.array(coef)\n",
    "        return X,coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n      = 10;\n",
    "model  = Model_cpu(input_dim=SYS.dim,num_hidden=2,hidden_dim=50,n=n)\n",
    "solver = Solver(model,q0=-5,q1=5)\n",
    "model.load_state_dict(torch.load(\"saved_models/SL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"Example1_data/SL\")) \n",
    "\n",
    "q_list = np.linspace(0,1,10)\n",
    "US   = UmbrellaSampling(kappa=3000,q=q_list,eps=EPS,model=model)\n",
    "x0   = np.repeat(np.vstack([SYS.A,SYS.B]),[5,5],axis=0)\n",
    "data = US.get_data_Parallel(x0,get_dV=SYS.get_dV,dt=1e-5,m=100,T0=3,T=8,n=1);\n",
    "\n",
    "# ShowQandSampledData([model.get_q,model.get_q],states=[[X_u2],[]],titles=['NN','FEM'])\n",
    "ShowQandSampledData([model.get_q,model.get_q],states=[[],[]],titles=['NN','NN'])\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5));\n",
    "[ax[0].hist(model.get_q(d),15) for d in data]\n",
    "# [ax[1].hist(get_q_FEM(d),15) for d in data]\n",
    "[ax[k].set_xlim([0,1]) for k in range(2)]\n",
    "[ax[k].set_title(s,fontsize=15) for k,s in enumerate(['NN','FEM'])];\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e629121",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,coef = US.get_X_coef(data);\n",
    "print(X.shape)\n",
    "def down_sample2(X,coef):\n",
    "    mask = SYS.IsInA(X) | SYS.IsInB(X)\n",
    "    return X[~mask],coef[~mask]\n",
    "X,coef = down_sample2(X,coef)\n",
    "\n",
    "data_train,data_test = get_train_test(X,coef,X_A,X_B,ratio=.9)\n",
    "for i in range(len(data_train)): print(data_train[i].shape,data_test[i].shape)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=torch.tensor(learning_rate))\n",
    "solver.train_model(data_train=data_train,data_test=data_test,c1=c1,c2=c2,batch_size=5000,\n",
    "                   optimizer=optimizer,n_steps=int(20000+1),n_show_loss=1000,use_tqdm=True,\n",
    "                   error_model1=Error_Model,error_model2=Error_Model2)\n",
    "ShowQandSampledData([get_q_FEM,model.get_q],states=[[],[X]],\n",
    "                    titles=['Ref.','Umbrella Sampling']) \n",
    "\n",
    "np.savez(\"US_data/SL_US_data\",data)\n",
    "torch.save([X,coef],'US_data/SL_US_X_coef')\n",
    "torch.save(model.state_dict(), 'saved_models/SL_US_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765346e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
